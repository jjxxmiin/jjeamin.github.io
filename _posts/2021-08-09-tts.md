---
layout: post
title:  "Text to Speech"
summary: "Tacotron2 + WaveNet"
date:   2021-08-05 09:10 -0400
categories: news
math: true
---

- Paper : [https://arxiv.org/abs/1712.05884v2](https://arxiv.org/abs/1712.05884v2)


재밌는게 생각이 나서 TTS를 하고싶은데 지식이 없어 이 참에 공부해보겠습니다. (논문 리뷰는 아닙니다.)

딥러닝을 이용한 TTS 자료들이 많지는 않은데

- [https://www.slideshare.net/carpedm20/deview-2017-80824162](https://www.slideshare.net/carpedm20/deview-2017-80824162)
- [https://joungheekim.github.io/2020/09/25/paper-review/](https://joungheekim.github.io/2020/09/25/paper-review/)
- [https://joungheekim.github.io/2020/10/08/paper-review/](https://joungheekim.github.io/2020/10/08/paper-review/)

위에 잘 정리되어있는 것 같습니다.

---

딥러닝을 사용한 TTS는 WaveNet과 Tacotron으로 많은 발전이 이루어진 것 같습니다. 이게 일단 어떻게 동작하냐면...


```
(Text) -> Tacotron2 -> (Mel Spectrogram) -> WaveNet -> (Audio Digital Data)
```

보통 WaveNet을 Vocoder라고 부릅니다. 기존엔 WaveNet이 아니라 Griffin-Lim이라는 모듈이 있었습니다. 모르는 용어는 밑에서 천천히 알아봅시다.

먼저 흐름을 익히면

1. Text를 Character로 쪼갠 뒤 Embedding합니다.
2. Tacotron은 Encoder, Attetnion, Decoder로 구성되며 Mel Spectrogram을 출력합니다.
3. Mel Spectrogram을 WaveNet에 넣어서 Voice를 만들면 됩니다.

전처리는 보통...

```
Audio Digital Data -(STFT)-> Spectrogram -(Mel-Filter Bank)-> Mel Spectrogram
```

---

## Mel Spectrogram


## Griffin-Lim

- Linear Spectrogram -> Audio Digital Data 알고리즘 입니다.
- 이와 같은 역할을 하는 WaveNet(Vocoder)보다 빠릅니다.

---

# Tacotron



![figure0](/_posts/post_img/tts/tacotron.png)






![figure0](/assets/img/post_img/tts/tacotron.jpg)



Tacotron 모델 구조

# Tacotron
