---
layout: post
title:  "pix2pix-tensorflow"
summary: "pix2pix 구현하기"
date:   2019-02-26 09:00 -0400
categories: gan
---
[깃허브](https://github.com/jjeamin/my_gan/tree/master/pix2pix)
# requirement
- python 3
- scipy
- tensorflow

---

# dataset
- [https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets](https://people.eecs.berkeley.edu/~tinghuiz/projects/pix2pix/datasets)

---

# File
- reader
- pix2pix
- train

---

# 개념
## L1 loss
정규화의 일종. 모델 가중치 **각 요소 절대값의 합** 에 대해 패널티를 부과한다. 불필요한 특징에 대응하는 가중치들을 정확히 0으로 만들어 해당 특징을 무시하도록 만든다. **변수선택** 효과가 있다.

```
L1 = tf.reduce_mean(tf.abs(train - input))
```

## L2 loss
정규화의 일종. 모델 가중치 **각 요소 제곱의 합** 에 대해 패널티를 부과한다. 아주 큰 값이나 작은 값을 가지는 가중치에 대해 0에 가깝지만 0은 아닌 값으로 만든다.

```
L2 = tf.reduce_mean(tf.pow((train - input),2))
```

## input normalization
전체 구간을 -1~0 사이의 값으로 맞춰 준다.
교육이 더 빨라지고 local optima에 걸릴 확률이 줄어들 수 있다.

```
normalization = input * (2.0 / 255.0) - 1
```



![input_norm](https://github.com/jjeamin/jjeamin.github.io/raw/master/_posts/post_img/pix2pix/input_norm.PNG)




## loss가 nan값이 되는 문제
log 함수는 진수가 0이 될때 음의 무한대가 되어버리기 때문에 발생한다.
- 해결 방법
```
tf.reduce_mean(tf.log(d_real + (1e-10)) + tf.log(1 - d_fake + (1e-10)))
```
log 함수안에 le-10을 더해서 0이 나오는 것을 방지한다.

## skip-connection
- layer가 너무 깊어지면 학습이 잘 되지 않고, 성능이 떨어지는 문제를 해결
- 입력 데이터를 합성곱 계층을 건너서 decoder에 바로 더하는 구조 -> 신호 감쇠를 막는다.

## overfitting
- 너무 learning을 잘해서 test data를 인식하지 못한다.
- 데이터 양을 늘리기
- 일반화 regularization
- 지능적 훈련 데이터 사용(rotation,shearing,translation,scaling)
- dropout

## layer가 많을때 특징
- 학습 능력이 좋아진다.
- overfitting에 빠질 가능성이 높다.
- 학습시간이 길어진다.

## dropout
- 일부 뉴런을 생략하고 학습을 수행한다.
- voting 효과
- co-adaptation 효과
특정 뉴런의 bias나 weight가 큰 값을 갖게 되면 영향이 커지면서 다른 뉴런들의 학습 속도가 느려지거나 학습이 제대로 진행이 되지 못하는 경우가 있다. 그러나 dropout이 이를 방지할 수 있다.

---

# pix2pix



![model](https://github.com/jjeamin/jjeamin.github.io/raw/master/_posts/post_img/pix2pix/model.PNG)



출처 : [https://taeoh-kim.github.io/blog/gan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-image-to-image-translation-pix2pix-cyclegan-discogan/](https://taeoh-kim.github.io/blog/gan%EC%9D%84-%EC%9D%B4%EC%9A%A9%ED%95%9C-image-to-image-translation-pix2pix-cyclegan-discogan/)

## hyperparameter
- img_shape = [256,256,3]
- total_epoch = 200
- batch_size = 4
- learning_rate = 0.0002
- EPS = 1e-12
- keep_prob = 0.5


## generator
- **encoder**
- input image[256,256,3] -> 128x128x64
  + leaky_relu

- 128x128x64 -> 64x64x128
  + leaky_relu
  + batch_norm

- 64x64x128 -> 32x32x256
  + leaky_relu
  + batch_norm

- 32x32x256 -> 16x16x512
  + leaky_relu
  + batch_norm

- 16x16x512 -> 8x8x512
  + leaky_relu
  + batch_norm

- 8x8x512 -> 4x4x512
  + leaky_relu
  + batch_norm

- 4x4x512 -> 2x2x512
  + leaky_relu
  + batch_norm

- 2x2x512 -> 1x1x512
  + relu
  + batch_norm

- **decoder**
- 1x1x512 -> 2x2x512
  + dropout
  + relu
  + skip-connection

- 2x2x512 -> 4x4x512
  + dropout
  + relu
  + skip-connection

- 4x4x512 -> 8x8x512
  + dropout
  + relu
  + skip-connection

- 8x8x512 -> 16x16x512
  + dropout
  + relu
  + skip-connection

- 16x16x512 -> 32x32x256
  + dropout
  + relu
  + skip-connection  

- 32x32x256 -> 64x64x128
  + dropout
  + relu
  + skip-connection

- 64x64x128 -> 128x128x64
  + dropout
  + relu
  + skip-connection

- 128x128x64 -> 256x256x3
  + tanh

## discriminator
- input image[256,256,6] -> 128x128x64
  + leaky_relu

- 128x128x64 -> 64x64x128
  + leaky_relu
  + batch_norm

- 64x64x128 -> 32x32x256
  + leaky_relu
  + batch_norm

- 32x32x256 -> 31x31x512
  + leaky_relu
  + batch_norm

- 31x31x512 -> 30x30x1
  + sigmoid


## loss
```
d_cost = -tf.reduce_mean(tf.log(d_real + EPS) + tf.log(1 - d_fake + EPS))
```
- 진짜 이미지가 진짜라고 하길바란다
- 가짜 이미지가 가짜라고 하길바란다


```
g_cost_GAN = tf.reduce_mean(-tf.log(d_fake + EPS))
g_cost_L1 = tf.reduce_mean(tf.abs(target_img - gen_img))
g_cost = g_cost_GAN + g_cost_L1 * 100
```
- GAN : 가짜 이미지가 진짜라고 하길바란다
- L1 : target 이미지와 가짜 이미지의 차이를 줄이기를 바란다. (가짜이미지 -> target)

---

# 참조
- pix2pix
  + [https://medium.com/@ManishChablani/cyclegans-and-pix2pix-5e6a5f0159c4](https://medium.com/@ManishChablani/cyclegans-and-pix2pix-5e6a5f0159c4)
  + [https://github.com/HyeongminLEE/Tensorflow_Pix2Pix](https://github.com/HyeongminLEE/Tensorflow_Pix2Pix)
  + [https://wewinserv.tistory.com/71](https://wewinserv.tistory.com/71)
- 용어
  + [https://ratsgo.github.io/machine%20learning/2017/10/12/terms/](https://ratsgo.github.io/machine%20learning/2017/10/12/terms/)
- input normalization
  + [https://goodtogreate.tistory.com/entry/Neural-Network-%EC%A0%81%EC%9A%A9-%EC%A0%84%EC%97%90-Input-data%EB%A5%BC-Normalize-%ED%95%B4%EC%95%BC-%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0](https://goodtogreate.tistory.com/entry/Neural-Network-%EC%A0%81%EC%9A%A9-%EC%A0%84%EC%97%90-Input-data%EB%A5%BC-Normalize-%ED%95%B4%EC%95%BC-%ED%95%98%EB%8A%94-%EC%9D%B4%EC%9C%A0)
- why loss nan??
  + [https://m.blog.naver.com/PostView.nhn?blogId=ryu_seonghan&logNo=221008635465&proxyReferer=https%3A%2F%2Fwww.google.com%2F](https://m.blog.naver.com/PostView.nhn?blogId=ryu_seonghan&logNo=221008635465&proxyReferer=https%3A%2F%2Fwww.google.com%2F)
